# Audit Service Documentation

## Q. Problem Statement
**Implement the audit service for a microservices-based application**
### **Requirements:**
1. **Subscribe to Change Notifications**
    - The service listens for events from other microservices.
    - Processes and stores them in a **standard format** in the database.

2. **Audit Log APIs**
    - **Admin**: Can view **all** audit messages.
    - **Non-Admin**: Can view audit logs **only for accessible entities**.

3. **Log Rotation**
    - Implement **configurable log rotation** to prevent excessive data growth.

4. **Spring Boot-based**
    - The application must be developed using **Spring Boot**.

5. **Deployment**
    - Deploy as a **WAR file** in **Tomcat** on a **CentOS VM**.

### **Design Considerations:**
1. **Database Choice & Schema Design**
    - Optimize for **performance** with indexing and partitioning.

2. **Audit Message Format**
    - Standardize the JSON format for consistency.

3. **Intra-service Communication**
    - Use **Kafka** for event-driven logging.

4. **Tamper-proofing**
    - Implement **cryptographic hashing** to prevent log manipulation.

5. **Cross-platform Deployment**
    - Ensure compatibility across **Linux**, **Windows**, and **cloud platforms**.

6. **Scalability**
    - Design for **horizontal scaling** and **high availability**.

---
## A Note from the Developer

“This Audit Service is implemented based on my current understanding of secure and scalable logging in a microservices architecture. While it meets the core requirements, there is always room for improvement in design, performance, and security. The project can be further enhanced with additional features, optimizations, and best practices as needed. Feedback is welcome!”

---
## Description
The **Audit Service** is a microservice responsible for recording and storing audit logs generated by various services within a system. It ensures that all actions performed by users and services are logged securely and tamper-proof. The service leverages **Kafka** for event-driven message processing, **MongoDB** for scalable and flexible log storage, and **JWT (JSON Web Token)** for secure authentication and authorization.

---

## Features
- **JWT Authentication** for secure access
- **Kafka Integration** to process audit events
- **MongoDB** for storing logs efficiently
- **RSA Signature** to ensure log integrity
- **Dockerized Deployment** for portability

---

## JWT Authentication

### How JWT Works in This Project?
1. **User logs in** → Backend verifies credentials.
2. **JWT Token is issued** → Contains user roles & expiry.
3. **Client sends JWT with requests** → Backend verifies.
4. **Role-based access** ensures only authorized users access logs.

### JWT Structure
```json
{
  "alg": "HS256",
  "typ": "JWT"
}
{
  "sub": "test-125",
  "iat": 1741165477,
  "exp": 1741175477
}
```

---
## Kafka

### Why Kafka?
Kafka is used for **asynchronous, distributed, and fault-tolerant event streaming**. It ensures that audit logs are processed **at scale** without impacting the performance of microservices.

### Why Not Other Message Brokers?
| Broker        | Reason for Not Choosing |
|---------------|------------------------|
| RabbitMQ      | Not designed for event streaming at scale |
| ActiveMQ      | Lacks distributed, partitioned architecture |
| Redis Pub/Sub | Not durable, no event retention |

### How Kafka Fits in the Use Case?
1. **Producers (Microservices)** send audit logs as Kafka messages.
2. **Audit Service (Consumer)** listens, validates, and stores the logs in MongoDB.
3. Kafka ensures **high availability & fault tolerance**.

---

## MongoDB

### Why MongoDB?
- NoSQL document storage is **flexible** for dynamic audit structures.
- **High write performance** for large-scale event logging.
- Supports **indexing & partitioning** for optimized queries.

### Why Not Other Databases?
| Database   | Reason for Not Choosing |
|------------|------------------------|
| PostgreSQL | Rigid schema, lower write performance for logs |
| MySQL      | Lacks NoSQL flexibility for JSON-like logs |
| Cassandra  | Complex setup, less community support |

### How MongoDB Fits in the Use Case?
- Stores audit logs **as JSON documents**.
- Uses **indexes** for fast retrieval.
- Scalable and supports **high-throughput writes**.

---

## API signatures

### Authentication API
### 1. User Signup

#### Endpoint: POST http://localhost:8080/auth/signup

#### Request Body:
```json
{
  "userName": "userA",
  "password": "1234567"
}
```
#### Response:
```json
{
  "id": {
    "timestamp": 1714224562,
    "date": "2025-03-06T06:29:22.000+00:00"
  },
  "userId": "e60949a9-9bd8-4b4c-9eed-0ec7bcb832354",
  "password": "S2A5lnQS6J7CkgX.CYNQ3x.8OkA2oKNZtA4jzn.wkPJ.0tEUE0HR8Y6Yb.",
  "createdAt": "2025-03-06T06:29:22.000Z",
  "updatedAt": "2025-03-06T06:29:22.000Z",
  "role": {
    "id": {
      "timestamp": 1714165219,
      "date": "2025-03-05T09:19:00.000+00:00"
    },
    "name": "USER",
    "description": "Default user role",
    "createdAt": "2025-03-05T09:19:00.002",
    "updatedAt": "2025-03-05T09:19:00.002"
  },
  "enabled": true,
  "authorities": [
    {
      "authority": "ROLE_USER"
    }
  ],
  "username": "userA",
  "accountNonExpired": true,
  "accountNonLocked": true,
  "credentialsNonExpired": true
}
```

### 2. User Login

#### Endpoint: POST http://localhost:8080/auth/login
#### Request Header: "Content-Type: application/json"
#### Request Body:
```json

{
  "userName": "userA",
  "password": "1234567"
}
```
#### Response:
```json
{
  "token": "eyJhbGciOiJIUzI1NiJ9...",
  "expiresIn": 3600000
}
```

### 3. Admin Signup
